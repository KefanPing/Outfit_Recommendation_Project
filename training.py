# -*- coding: utf-8 -*-
"""style_5_27.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wy1oSnK01iiYRwUf4Rc4Y1rxyb_LTpu2
"""

# packages in this training file

from training_module import *

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow import keras

from tensorflow.keras.preprocessing import image

from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras.layers.experimental.preprocessing import StringLookup

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

import cv2

import matplotlib.image as mpimg

# connect with google while working on colab
from google.colab import drive
drive.mount('/content/drive')



#use to unzip data

from zipfile import ZipFile
file_name = "archive.zip"

with ZipFile(file_name, 'r') as zip:
  zip.extractall()
  print('Done')

def group_color(styles):
    styles["colorgroup"] = -1
    styles.loc[(styles.baseColour=='Red')|
           (styles.baseColour=='Brown')|
           (styles.baseColour=='Coffee Brown')|
           (styles.baseColour=='Maroon')|
           (styles.baseColour=='Rust')|
           (styles.baseColour=='Burgundy')|
           (styles.baseColour=='Mushroom Brown'),"colorgroup"] = 0
    styles.loc[(styles.baseColour=='Copper'),"colorgroup"] = 1
    styles.loc[(styles.baseColour=='Orange')|
               (styles.baseColour=='Bronze')|
               (styles.baseColour=='Skin')|
               (styles.baseColour=='Nude'),"colorgroup"] = 2
    styles.loc[(styles.baseColour=='Gold')|
               (styles.baseColour=='Khaki')|
               (styles.baseColour=='Beige')|
               (styles.baseColour=='Mustard')|
               (styles.baseColour=='Tan')|
               (styles.baseColour=='Metallic'),"colorgroup"]= 3
    styles.loc[(styles.baseColour=='Yellow'),"colorgroup"] = 4
    styles.loc[(styles.baseColour=='Lime Green'),"colorgroup"]= 5
    styles.loc[(styles.baseColour=='Green')|
           (styles.baseColour=='Sea Green')|
           (styles.baseColour=='Fluorescent Green')|
           (styles.baseColour=='Olive'),"colorgroup"] = 6
    styles.loc[(styles.baseColour=='Teal')|
           (styles.baseColour=='Turquoise Blue'),"colorgroup"] = 7
    styles.loc[(styles.baseColour=='Blue'),"colorgroup"]= 8
    styles.loc[(styles.baseColour=='Navy Blue'),"colorgroup"] = 9
    styles.loc[(styles.baseColour=='Purple')|
           (styles.baseColour=='Lavender'),"colorgroup"] = 10
    styles.loc[(styles.baseColour=='Pink')|
           (styles.baseColour=='Magenta')|
           (styles.baseColour=='Peach')|
           (styles.baseColour=='Rose')|
           (styles.baseColour=='Mauve'),"colorgroup"] = 11
    styles.loc[(styles.baseColour=='Black')|
           (styles.baseColour=='Charcoal'),"colorgroup"] = 12
    styles.loc[(styles.baseColour=='White')|
           (styles.baseColour=='Off White')|
           (styles.baseColour=='Cream'),"colorgroup"] = 13
    styles.loc[(styles.baseColour=='Grey')|
           (styles.baseColour=='Silver')|
           (styles.baseColour=='Taupe')|
           (styles.baseColour=='Grey Melange'),"colorgroup"] = 14
    styles.loc[(styles.baseColour=='Multi'),"colorgroup"] = 15  
    

def df_drop(styles, col, item):
    """
    This function drops certain columns
    input: styles, dataframe
        col, the item we want to drop in this coloumn
        item, which item we want to drop 
    """
    for i in item:
        styles = styles.drop(styles[styles[col] == i].index)
    return styles

def get_df():
  """
  this function get and clean the data, return a dataframe
  """
    styles = pd.read_csv("styles.csv", error_bad_lines=False)
    styles = styles.drop(["productDisplayName"],axis = 1) #drop useless column, we do not need name to do recommendation
    styles = styles.drop(["year"],axis = 1) #drop useless column, we do not need year to do recommendation
    styles = styles[(styles.masterCategory=='Apparel')| (styles.masterCategory=='Footwear')] # drop useless rows, we are not recommend acessories
    styles = styles.drop(styles[styles["subCategory"] == "Innerwear"].index) # drop useless row, we are not recommend innerwears, only outfits.
    styles = styles.dropna() # drop NA
    styles = df_drop(styles,"subCategory", ["Apparel Set", "Dress","Loungewear and Nightwear","Saree","Socks"]) # we only recommend outfits.
    styles["subCategory"] = styles["subCategory"].transform(lambda x: "Footwear" if(x in ["Shoes","Flip Flops","Sandal"]) else x) # Group them into one category.
    styles = styles.drop(labels=[6695,16194,32309,36381,40000], axis=0) # drop incomplete rows
    group_color(styles) # group the color in to color-wheel
    return styles

styles = get_df()

styles["subCategory"].unique() # we can check by this code that we only have three subcategory now.

"""# Model-1: """

def make_input_array_subcate(df):
  """
  This function get the dataset 
  input: dataframe
  output: dataset
  """
    train_images = np.zeros((len(df.id),80,60,3))
    for i in range(len(df.id)):
        
        #try:
        ID = df.id.iloc[i]
        path = f"images/{ID}.jpg"#/content/images   
        img = cv2.imread(path)
        if img.shape != (80,60,3):
            img = image.load_img(path, target_size=(80,60,3))

        #except:
            #print(ID)
        
        train_images[i] = img
    
    data = tf.data.Dataset.from_tensor_slices(
      (
        {
          "images" : train_images
       },

        {
          "subCategory" : df[["subCategory"]]
        }
      )
    )

    return data

le = LabelEncoder()
#
styles["subCategory"] = le.fit_transform(styles["subCategory"])




styles.head()

le.classes_

def make_branch(res_input, n_out, act_type, name):
  """
  This function build the branch
  input: res_input, keras.Input
      n_out: length of output
      act_type: type of activation
      name: output name
  """
    z = layers.Dense(512, activation="relu")(res_input)
    z = layers.Dense(256, activation='relu')(z)
    z = layers.Dense(128, activation='relu')(z)
    z = layers.Dense(64, activation='relu')(z)

    z = layers.Dense(n_out)(z)
    z = layers.Activation(act_type, name=name)(z)
    return z

def build_model(width, height):
  """
  This function build a model
  input: width, width of image
      height, height of image
  output: machinelearning model
  """

    # -------------------------
    res50 = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(80,60,3))
    res50.trainable=False
    inputs = keras.Input(shape=(width,height,3),name = "images")
    x = res50(inputs, training=False)
    x = layers.Conv2D(32, (2, 2), activation='relu')(x)
    x = layers.Flatten()(x)
    x = layers.Dense(1024, activation='relu')(x)
    # -------------------------

    sub_branch = make_branch(x, len(le.classes_), 'softmax', 'subCategory')

    model = keras.Model(inputs=inputs,
                outputs=[sub_branch]
                       )
    return model

def make_input_xx(x):#make_input_array_subcate(styles)
  """
  get the traing testing validation data
  input: x, input dataset
  output: x_train, training dataset
      x_val,validation dataset
      x_test, testing dataset
  """
  x_input = x
  x_input = x_input.shuffle(buffer_size = len(x_input))

  x_train_size = int(0.6*len(x_input))
  x_val_size   = int(0.2*len(x_input))

  x_train = x_input.take(x_train_size).batch(2)
  x_val   = x_input.skip(x_train_size).take(x_val_size).batch(2)
  x_test  = x_input.skip(x_train_size + x_val_size).batch(2)

  return x_train,x_val,x_test

sub_train,sub_val,sub_test = make_input_xx(make_input_array_subcate(styles))

sub_model = build_model(80, 60)

sub_model.summary()

from tensorflow.keras.utils import plot_model
plot_model(sub_model)

sub_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

sub_history = sub_model.fit(sub_train, 
                    epochs=5, 
                    steps_per_epoch = 2000,
                    validation_data = sub_val)

sub_model.save("/content/drive/MyDrive/models/model_sub")

test_model = tf.keras.models.load_model("/content/drive/MyDrive/models/model_sub")

test_model.evaluate(sub_test)

"""# Model 234"""

def my_le(styles):
  """
  This function encode the data 
  input: styles, dataframe we want to encode
  output; styles, dataframe we encoded
      articleTypeLB,genderLB,baseColourLB,seasonLB,usageLB : all the labelEncoders
  """
  articleTypeLB = LabelEncoder()
  genderLB = LabelEncoder()
  baseColourLB = LabelEncoder()
  seasonLB = LabelEncoder()
  usageLB = LabelEncoder()


  #


  styles['articleType'] = articleTypeLB.fit_transform(styles['articleType'])
  styles['gender'] = genderLB.fit_transform(styles['gender'])
  styles['baseColour'] = baseColourLB.fit_transform(styles['baseColour'])
  styles['season'] = seasonLB.fit_transform(styles['season'])
  styles['usage'] = usageLB.fit_transform(styles['usage'])
  return styles,articleTypeLB,genderLB,baseColourLB,seasonLB,usageLB

def get_234_df(x):
  """
  This function get the dataframe for model2.1,2.2,2.3
  input: x, the col we want
  output: the dataframe only for x
  """
    styles = pd.read_csv("styles.csv", error_bad_lines=False)
    styles = styles.drop(["productDisplayName"],axis = 1)
    styles = styles.drop(["year"],axis = 1)
    styles = styles[(styles.masterCategory=='Apparel')| (styles.masterCategory=='Footwear')]
    styles = styles.drop(styles[styles["subCategory"] == "Innerwear"].index)
    styles = styles.dropna()
    styles = df_drop(styles,"subCategory", ["Apparel Set", "Dress","Loungewear and Nightwear","Saree","Socks"])
    styles["subCategory"] = styles["subCategory"].transform(lambda x: "Footwear" if(x in ["Shoes","Flip Flops","Sandal"]) else x)
    styles = styles.drop(labels=[6695,16194,32309,36381,40000], axis=0)
    styles = styles[styles.subCategory == x]
    group_color(styles)
    styles.baseColour=styles.colorgroup

    return styles

def build_model(width, height, articleTypeLB,genderLB,baseColourLB,seasonLB,usageLB):
  """
  build the machine learning model. similar to the previous one
  """

    # -------------------------
    res50 = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(80,60,3))
    res50.trainable=False
    inputs = keras.Input(shape=(width,height,3),name = "images")
    x = res50(inputs, training=False)
    
    x = layers.Flatten()(x)
    x = layers.Dense(1024, activation='relu')(x)
    # -------------------------

    article_branch = make_branch(x, len(articleTypeLB.classes_), 'softmax', 'articleType')
    gender_branch = make_branch(x, len(genderLB.classes_), 'softmax', 'gender')
    color_branch = make_branch(x, len(baseColourLB.classes_), 'softmax', 'baseColour')
    season_branch = make_branch(x, len(seasonLB.classes_), 'softmax', 'season')
    usage_branch = make_branch(x, len(usageLB.classes_), 'softmax', 'usage')

    model = keras.Model(inputs=inputs,
                outputs=[article_branch, gender_branch, color_branch, 
                            season_branch, usage_branch]
                       )
    return model

top_df = get_234_df("Topwear")
bottom_df = get_234_df("Bottomwear")
foot_df = get_234_df("Footwear")

top_df,top_art,top_gen,top_base,top_sea,top_usage = my_le(top_df)
bottom_df,bottom_art,bottom_gen,bottom_base,bottom_sea,bottom_usage = my_le(bottom_df)
foot_df,foot_art,foot_gen,foot_base,foot_sea,foot_usage = my_le(foot_df)

foot_usage.classes_

top_base_model = build_model(80,60,top_art,top_gen,top_base,top_sea,top_usage)
bottom_base_model = build_model(80,60,bottom_art,bottom_gen,bottom_base,bottom_sea,bottom_usage)
foot_base_model = build_model(80,60,foot_art,foot_gen,foot_base,foot_sea,foot_usage)

def make_input_array_2(df):
  """
  make the input dataset. similar to the previous one.
  """
    train_images = np.zeros((len(df.id),80,60,3))
    for i in range(len(df.id)):
        
        #try:
        ID = df.id.iloc[i]
        path = f"images/{ID}.jpg"#/content/images   
        img = cv2.imread(path)
        if img.shape != (80,60,3):
            img = image.load_img(path, target_size=(80,60,3))

        #except:
            #print(ID)
        
        train_images[i] = img
    
    data = tf.data.Dataset.from_tensor_slices(
      (
        {
          "images" : train_images
       },

        {
          "articleType" : df[["articleType"]],
            'gender' : df[['gender']],
            'baseColour' : df[['baseColour']],
            'season' : df[['season']],
            'usage' : df[['usage']]
            
        }
      )
    )

    return data

top_train, top_val, top_test = make_input_xx(make_input_array_2(top_df))
bottom_train, bottom_val, bottom_test = make_input_xx(make_input_array_2(bottom_df))
foot_train, foot_val, foot_test = make_input_xx(make_input_array_2(foot_df))

top_base_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
bottom_base_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
foot_base_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

top_history = top_base_model.fit(top_train, 
                    epochs=10, 
                    steps_per_epoch = 500,
                    validation_data = top_val)

top_base_model.evaluate(top_test)

top_base_model.save("/content/drive/MyDrive/model_2.1")



bottom_history = bottom_base_model.fit(bottom_train, 
                    epochs=15, 
                    steps_per_epoch = 50,
                    validation_data = bottom_val)

bottom_base_model.evaluate(bottom_test)

bottom_base_model.save("/content/drive/MyDrive/models/model_2.2")



foot_history = foot_base_model.fit(foot_train, 
                    epochs=5, 
                    steps_per_epoch = 2000,
                    validation_data = foot_val)

foot_base_model.evaluate(foot_test)

foot_base_model.save("/content/drive/MyDrive/model_2.2")

#!zip -r '"foot_model.zip"' '"foot_model"'

"""# Model.2_1 predict which type of top wear"""

styles = get_df()
styles.head()





styles_model = build_model(80,60)

styles_model.summary()

from tensorflow.keras.utils import plot_model
plot_model(styles_model)

styles_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

styles_history = styles_model.fit(styles_train, 
                    epochs=40, 
                    steps_per_epoch = 200,
                    validation_data = styles_val)

styles_model.evaluate(styles_test)

#path = ''
#Top_model.save(path)





